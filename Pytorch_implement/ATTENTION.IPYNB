{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x121c024d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions\n",
    "batch_size = 2    # number of sequences in the batch\n",
    "seq_length = 4    # number of tokens in each sequence\n",
    "d_model = 8       # embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input: a batch of sequences of token embeddings\n",
    "# Shape: [batch_size, seq_length, d_model]\n",
    "x = torch.rand(batch_size, seq_length, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projection:\n",
    "Three different weight matrices (W_q, W_k, and W_v) are used to linearly project the input embeddings into queries (Q), keys (K), and values (V)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weight matrices for projecting the inputs to queries, keys, and values.\n",
    "# In a learned model these would be parameters of nn.Linear layers.\n",
    "W_q = torch.randn(d_model, d_model)\n",
    "W_k = torch.randn(d_model, d_model)\n",
    "W_v = torch.randn(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the inputs to Q, K, V\n",
    "# The resulting shapes: [batch_size, seq_length, d_model]\n",
    "Q = torch.matmul(x, W_q)\n",
    "K = torch.matmul(x, W_k)\n",
    "V = torch.matmul(x, W_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Scores:\n",
    "The dot product between Q and the transpose of K is computed for each sequence, resulting in a score matrix of shape [batch_size, seq_length, seq_length].\n",
    "These scores are scaled by d_model to maintain stable gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the scaled dot-product attention scores.\n",
    "# scores shape: [batch_size, seq_length, seq_length]\n",
    "# We compute Q * K^T for each element in the batch.\n",
    "scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_model, dtype=torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax to obtain attention weights. The softmax is applied on the last dimension.\n",
    "attn_weights = F.softmax(scores, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the final attention output as the weighted sum of the values.\n",
    "# Output shape: [batch_size, seq_length, d_model]\n",
    "attn_output = torch.matmul(attn_weights, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([2, 4, 8])\n",
      "Queries Q shape: torch.Size([2, 4, 8])\n",
      "Keys K shape: torch.Size([2, 4, 8])\n",
      "Values V shape: torch.Size([2, 4, 8])\n",
      "Scores shape: torch.Size([2, 4, 4])\n",
      "Attention Weights shape: torch.Size([2, 4, 4])\n",
      "Attention Output shape: torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "# Print shapes and values for inspection\n",
    "print(\"Input x shape:\", x.shape)\n",
    "print(\"Queries Q shape:\", Q.shape)\n",
    "print(\"Keys K shape:\", K.shape)\n",
    "print(\"Values V shape:\", V.shape)\n",
    "print(\"Scores shape:\", scores.shape)\n",
    "print(\"Attention Weights shape:\", attn_weights.shape)\n",
    "print(\"Attention Output shape:\", attn_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention Weights:\n",
      " tensor([[[0.1208, 0.4147, 0.0720, 0.3925],\n",
      "         [0.1173, 0.5753, 0.0603, 0.2471],\n",
      "         [0.1112, 0.4619, 0.0702, 0.3567],\n",
      "         [0.1528, 0.4312, 0.1098, 0.3061]],\n",
      "\n",
      "        [[0.1542, 0.3456, 0.1380, 0.3622],\n",
      "         [0.0951, 0.4722, 0.2063, 0.2265],\n",
      "         [0.0795, 0.0594, 0.7971, 0.0640],\n",
      "         [0.2178, 0.2033, 0.1923, 0.3866]]])\n",
      "\n",
      "Attention Output:\n",
      " tensor([[[-0.1093,  0.1661,  1.3634,  0.7949, -0.6423,  0.6541,  1.7390,\n",
      "          -1.2077],\n",
      "         [-0.1311,  0.1290,  1.2045,  0.7495, -0.4215,  0.4963,  1.5629,\n",
      "          -1.0194],\n",
      "         [-0.1063,  0.1598,  1.3230,  0.7857, -0.5873,  0.6143,  1.6820,\n",
      "          -1.1566],\n",
      "         [-0.2032,  0.1623,  1.2805,  0.7886, -0.5417,  0.6091,  1.7694,\n",
      "          -1.1958]],\n",
      "\n",
      "        [[-0.7167,  0.3874,  0.9260,  0.4987, -0.4800,  1.2840,  1.6569,\n",
      "          -1.6015],\n",
      "         [-0.6674,  0.2024,  1.0323,  0.4462, -0.3512,  1.2285,  1.5263,\n",
      "          -1.5770],\n",
      "         [-0.0712,  0.4308,  0.5893,  1.1798, -0.0718,  1.2751,  0.4999,\n",
      "          -2.8038],\n",
      "         [-0.6690,  0.4609,  0.7889,  0.6240, -0.4964,  1.3023,  1.6103,\n",
      "          -1.8216]]])\n"
     ]
    }
   ],
   "source": [
    "# Optionally, print the computed tensors (or a summary) to see the actual values.\n",
    "print(\"\\nAttention Weights:\\n\", attn_weights)\n",
    "print(\"\\nAttention Output:\\n\", attn_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
